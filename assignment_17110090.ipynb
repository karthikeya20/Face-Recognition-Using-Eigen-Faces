{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FACE RECOGNITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***This part of the code is to filter the images and get the faces properly and resize them for better results***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered images\n"
     ]
    }
   ],
   "source": [
    "rows,columns=400,400\n",
    "def facecrop(i):\n",
    "    facedata = \"haarcascade_frontalface_alt.xml\"\n",
    "    cascade = cv2.CascadeClassifier(facedata)\n",
    "    image=Image.open('YaleFaceDatabase/'+i).convert('L')\n",
    "    img=np.array(image,'uint8')\n",
    "    img= cv2.merge([img,img,img])\n",
    "    minisize = (img.shape[1],img.shape[0])\n",
    "    miniframe = cv2.resize(img, minisize)\n",
    "    faces = cascade.detectMultiScale(miniframe)\n",
    "    \n",
    "    for f in faces:\n",
    "        x, y, w, h = [ v for v in f ]\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (255,255,255))\n",
    "        sub_face = img[y:y+h, x:x+w]\n",
    "        gray = cv2.cvtColor(sub_face, cv2.COLOR_BGR2GRAY)\n",
    "        resized = cv2.resize(gray, (rows,columns), interpolation = cv2.INTER_AREA)\n",
    "        k=i.replace('.','_')\n",
    "        cv2.imwrite('images_gray/'+k+'.jpg', resized)\n",
    "    return\n",
    "images= os.listdir('./YaleFaceDatabase')\n",
    "all_images=[]\n",
    "for i in images:\n",
    "    facecrop(i)\n",
    "print('filtered images')\n",
    "           \n",
    "           \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Sample image with its description***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensions :  (400, 400)\n",
      "type :  gray\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_image=cv2.imread('images_gray/subject15_happy.jpg',0)\n",
    "print('dimensions : ',sample_image.shape)\n",
    "print('type : ','gray')\n",
    "cv2.imshow('Sample',sample_image)\n",
    "cv2.waitKey()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The Code for PCA (dimensionality reduction)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "images= os.listdir('./images_gray')\n",
    "all_names=[]\n",
    "all_images=[]\n",
    "# 8 out of 11 of each\n",
    "test_names=[]\n",
    "test_images=[]\n",
    "# 3 out of 11 of each\n",
    "\n",
    "#testsplit= 73 : 27\n",
    "for i in range(len(images)):\n",
    "    k=cv2.imread('images_gray/'+images[i],0)\n",
    "    arr=np.array(k)\n",
    "    arr1=np.reshape(arr,(1,-1))\n",
    "    if i%11<=7:\n",
    "        all_images.append(arr1)\n",
    "        all_names.append(images[i])\n",
    "    else:\n",
    "        test_images.append(arr1)\n",
    "        test_names.append(images[i])\n",
    "l=np.mean( np.array(all_images), axis=0)\n",
    "mean_of_imgs=l\n",
    "cv2.imshow('Mean',np.array(np.reshape(l,(rows,-1)),dtype = np.uint8))\n",
    "cv2.waitKey()\n",
    "all_im_mean=[]\n",
    "for i  in all_images:\n",
    "\tall_im_mean.append((i-l)[0])\n",
    "all_im_mean=np.array(all_im_mean)\n",
    "A=np.transpose(all_im_mean)\n",
    "A_t=np.transpose(A)\n",
    "cov=np.matmul(A_t,A)\n",
    "#print(cov)\n",
    "w, v = LA.eig(cov)\n",
    "di=[[] for i in range(len(w))]\n",
    "k1=np.array(sorted(w)[::-1])\n",
    "for i in range(len(w)):\n",
    "\tdi[i]=[w[i],v[i].tolist()]\n",
    "k5=k1/sum(k1)\n",
    "n=0\n",
    "s=0\n",
    "while(s<0.85):\n",
    "    s+=k5[n]\n",
    "    n+=1\n",
    "top=31\n",
    "req_vec=[]\n",
    "req_eigens=sorted(di)[::-1][:top]\n",
    "import cmath\n",
    "for i in req_eigens:\n",
    "    lr=[]\n",
    "    for j in i[1]:\n",
    "        lr.append(float(j.real))\n",
    "    req_vec.append(lr)\n",
    "req_eigens=np.array(req_vec).transpose()\n",
    "actual_eigens=np.matmul(A,req_eigens)\n",
    "norm_=np.linalg.norm(actual_eigens,axis=0)\n",
    "actual_eigens=actual_eigens/norm_\n",
    "actual_eigens=actual_eigens.T\n",
    "all_weights=np.matmul(actual_eigens,A)\n",
    "all_weights=all_weights.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***This is for viewing the projections of all faces using the eigen basis***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trans_imgs=[]\n",
    "c1=0\n",
    "for i in range(len(all_images)):\n",
    "    c1+=1\n",
    "    s=[0 for m in range(rows*columns)]\n",
    "    for j in range(len(actual_eigens)):\n",
    "        s=np.add(np.array(s),np.array(actual_eigens[j])*all_weights[i][j])\n",
    "    l=l.T\n",
    "    l=l.flatten()\n",
    "    s=s+l\n",
    "    if c1<=3:\n",
    "    # showing only 3 for simplicity\n",
    "        cv2.imshow('actual_image',np.array(np.reshape(np.array(all_images[i]),(rows,-1)),dtype = np.uint8))\n",
    "        cv2.imshow('projection',np.array(np.reshape(np.array(s),(rows,-1)),dtype = np.uint8))\n",
    "        cv2.waitKey()\n",
    "    all_trans_imgs.append(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Testing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  |  actual_name:  subject15  |  predicted_name:  subject15\n",
      "2  |  actual_name:  subject01  |  predicted_name:  subject01\n",
      "3  |  actual_name:  subject01  |  predicted_name:  subject01\n",
      "4  |  actual_name:  subject01  |  predicted_name:  subject01\n",
      "5  |  actual_name:  subject02  |  predicted_name:  subject02\n",
      "6  |  actual_name:  subject02  |  predicted_name:  subject02\n",
      "7  |  actual_name:  subject02  |  predicted_name:  subject02\n",
      "8  |  actual_name:  subject03  |  predicted_name:  subject03\n",
      "9  |  actual_name:  subject03  |  predicted_name:  subject10\n",
      "10  |  actual_name:  subject03  |  predicted_name:  subject03\n",
      "11  |  actual_name:  subject04  |  predicted_name:  subject04\n",
      "12  |  actual_name:  subject04  |  predicted_name:  subject04\n",
      "13  |  actual_name:  subject04  |  predicted_name:  subject04\n",
      "14  |  actual_name:  subject05  |  predicted_name:  subject05\n",
      "15  |  actual_name:  subject05  |  predicted_name:  subject05\n",
      "16  |  actual_name:  subject05  |  predicted_name:  subject05\n",
      "17  |  actual_name:  subject06  |  predicted_name:  subject06\n",
      "18  |  actual_name:  subject06  |  predicted_name:  subject06\n",
      "19  |  actual_name:  subject06  |  predicted_name:  subject06\n",
      "20  |  actual_name:  subject07  |  predicted_name:  subject07\n",
      "21  |  actual_name:  subject07  |  predicted_name:  subject07\n",
      "22  |  actual_name:  subject07  |  predicted_name:  subject12\n",
      "23  |  actual_name:  subject08  |  predicted_name:  subject08\n",
      "24  |  actual_name:  subject08  |  predicted_name:  subject08\n",
      "25  |  actual_name:  subject08  |  predicted_name:  subject08\n",
      "26  |  actual_name:  subject09  |  predicted_name:  subject09\n",
      "27  |  actual_name:  subject09  |  predicted_name:  subject15\n",
      "28  |  actual_name:  subject09  |  predicted_name:  subject09\n",
      "29  |  actual_name:  subject10  |  predicted_name:  subject10\n",
      "30  |  actual_name:  subject10  |  predicted_name:  subject14\n",
      "31  |  actual_name:  subject10  |  predicted_name:  subject10\n",
      "32  |  actual_name:  subject11  |  predicted_name:  subject11\n",
      "33  |  actual_name:  subject11  |  predicted_name:  subject11\n",
      "34  |  actual_name:  subject11  |  predicted_name:  subject11\n",
      "35  |  actual_name:  subject12  |  predicted_name:  subject12\n",
      "36  |  actual_name:  subject12  |  predicted_name:  subject12\n",
      "37  |  actual_name:  subject12  |  predicted_name:  subject12\n",
      "38  |  actual_name:  subject13  |  predicted_name:  subject13\n",
      "39  |  actual_name:  subject13  |  predicted_name:  subject13\n",
      "40  |  actual_name:  subject13  |  predicted_name:  subject13\n",
      "41  |  actual_name:  subject14  |  predicted_name:  subject14\n",
      "42  |  actual_name:  subject14  |  predicted_name:  subject14\n",
      "43  |  actual_name:  subject14  |  predicted_name:  subject14\n",
      "44  |  actual_name:  subject15  |  predicted_name:  subject15\n",
      "45  |  actual_name:  subject15  |  predicted_name:  subject15\n",
      "threshould:  20000\n",
      "____________________________________________________________\n",
      "accuracy:  91.11111111111111\n"
     ]
    }
   ],
   "source": [
    "test_img_centered=[]\n",
    "for i in test_images:\n",
    "\ttest_img_centered.append((i-l)[0])\n",
    "test_without_mean=np.array(test_img_centered)\n",
    "A_test=np.transpose(test_without_mean)\n",
    "test_weights=np.matmul(actual_eigens,A_test)\n",
    "test_weights=test_weights.T\n",
    "correct=0\n",
    "wrong=0\n",
    "threshould=20000\n",
    "\n",
    "for i in range(len(test_weights)):\n",
    "    print(i+1,' | ','actual_name: ',actual_name,' | ','predicted_name: ',predicted_name)\n",
    "    distances=[]\n",
    "    for j in all_weights:\n",
    "        distances.append(np.linalg.norm(j-test_weights[i]))\n",
    "    predicted_name=all_names[np.argmin(distances)]\n",
    "    predicted_name=predicted_name[:predicted_name.find('_')]\n",
    "    actual_name=test_names[i][:test_names[i].find('_')]\n",
    "    if (predicted_name==actual_name) and (min(distances)<threshould):\n",
    "        correct+=1\n",
    "    else:\n",
    "        wrong+=1\n",
    "    \n",
    "print('threshould: ',threshould)\n",
    "print('____________________________________________________________')\n",
    "print('accuracy: ',(correct/(correct+wrong))*100)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
